%!TEX root = ../../thesis.tex

% https://sci-hub.ru/https://doi.org/10.1016/j.sapharm.2020.10.013
% https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8409170/
% https://sci-hub.ru/10.1109/TMI.2009.2013851
% https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0068449

\chapter{Background}
\label{c:background}

This section is dedicated to providing the theoretical background which was needed for the study.\\
This section is structured as follows:
Fist, an introduction to the used similarity score will be given in %\cref{s:similarity-score}.
\\
Secondly,
% \cref{s:guide-creation}
will explain which criteria were considered on the creation of the segmentation guide.\\
Thirdly, evaluation of the segmentation\\
Finally,
%\cref{s:segmentation-theory}
will explain how parameters for correct segmentation were determined. %(TODO).

\section{\mct}
\label{s:b-microct}
Microscopic computed tomography (\mct) as a technology has been around since the 1980s and has since then emerged as the preclinical analogue of the clinical CT \cite{clarkAdvancesMicroCTImaging2021,ritmanCurrentStatusDevelopments2011}.
In comparison with clinical CT the \mct\space features high spacial resolution, which makes it irreplaceable for non-destructive small animal studies \cite{clarkAdvancesMicroCTImaging2021,ritmanCurrentStatusDevelopments2011,keklikoglouMicroCTBiologicalBiomedical2021}.

\subsection{Operating principle}
\label{s:b-mct-operation}
\mct\space technology is based upon the third-generation or so called ``rotate-rotate'' geometry of CT scanners \cite{flohrCTSystems2013}.
The basic principle in clinical CT being that both the X-ray source and the detector rotate around the patient table as part of a gantry assembly at the same time \cite{flohrCTSystems2013}.
A visual representation of this concept can be seen in \cref{fig:3ct}.
\begin{figure}[h]
	\centerline{
		\includegraphics[scale=0.5]{images/ct.png}}
	\caption{Third generation CT basic setup \cite{fdaDrawingCTFan2019}}
	\label{fig:3ct}
\end{figure}

\noindent
As can be seen in \cref{fig:3ct}, the animal or inanimate object is placed on a table between the X-ray source and the detector.
In clinical CT, the X-ray tube is designed to produce a fan shaped beam, which passes through the patient onto a concave detector array.
Whereas, in most \mct\space the X-ray source produces a cone or pyramid shaped beam, which passes through the patient onto a two-dimensional or flat detector \cite{babaComparisonFlatpanelDetector2002,clarkAdvancesMicroCTImaging2021}.
For reference see \cref{fig:mct}.
\begin{figure}[h]
	\centerline{
		\includegraphics[scale=0.5]{images/mct.png}}
	\caption{\mct\space basic setup\cite{orhanMicrocomputedTomographyMicroCT2020}}
	\label{fig:mct}
\end{figure}

\noindent
\mct\space X-ray sources usually use a fixed tungsten anode and therefore have to operate at lower voltage and current when compared to the rotating anode of clinical CT.
They can only achieve between 20 and 100\acrshort{kv} of tube voltage and between 0.05 and 1mA.
\begin{equation}\label{eqn:intensity-proportionality}
	I \propto (kV)^{2}*(mA)
\end{equation}
The number of X-ray photons depends on the tube current, and the energy of the photons depends on the tube voltage squared.
Furthermore, the intensity of the beam can be described as being proportional to the product of those two factors, see: \cref{eqn:intensity-proportionality}.
The flat panel detector usually contains a scintillator screen, which when excited by X-rays gives off visible light \cite{babaComparisonFlatpanelDetector2002,ritmanCurrentStatusDevelopments2011,clarkMicroCTRodentsStateart2014}.
This light is then detected with an image sensor, which can be either a \acrfull{ccd} or a \acrfull{cmos} image sensor \cite{babaComparisonFlatpanelDetector2002}.
\mct\space utilize high resolution flat panel detectors with pixel sizes less than 100 $\mu m^{2}$ \cite{clarkAdvancesMicroCTImaging2021,clarkMicroCTRodentsStateart2014}.
They can however, achieve \gls{iso} \gls{vx} sizes between 400 nm and 70 $\mu m$ \cite{orhanMicrocomputedTomographyMicroCT2020}.
To produce a scan the \mct\space captures several hundred, two dimension cone beam projections of different angles around the animal or object \cite{clarkMicroCTRodentsStateart2014,ritmanCurrentStatusDevelopments2011,clarkAdvancesMicroCTImaging2021}.
The rotation angles can be in 180$^{\circ}$ or 360$^{\circ}$ \cite{orhanMicrocomputedTomographyMicroCT2020}.
Image information can be described as the amount of attenuation of the X-ray beam at a specific path through the volume \cite{,orhanMicrocomputedTomographyMicroCT2020}.
This attenuation is described by the following \cref{eqn:attenuation}:
\begin{equation} \label{eqn:attenuation}
	I_{x} = I_{0}e^{- \mu x}
\end{equation}
\noindent
Where $I_{0}$ is the initial intensity of the beam, $x$ is the distance the beam traveled and $\mu$ is the linear \acrlong{ac}.
The linear \acrfull{ac} is different for every tissue and material and describes its X-ray density.
The result of \cref{eqn:attenuation} is $I_{x}$, the intensity of the beam at a distance $x$ from the source \cite{liMicrocomputedTomographySmall2008,orhanMicrocomputedTomographyMicroCT2020}.
This is performed simultaneously for all detector pixels in a single projection.
If the process is repeated for multiple angles in small steps (see: \cref{fig:ct-projections}) the attenuation value for every \gls{vx} in the scan volume can be found.
Generally speaking, increasing the amount of projections leads to a more accurate result \cite{liMicrocomputedTomographySmall2008,orhanMicrocomputedTomographyMicroCT2020}.
\begin{figure}[h]
	\centerline{
		\includegraphics[scale=0.5]{images/ct-projections.png}}
	\caption{\mct\space projections and reconstruction\cite{orhanMicrocomputedTomographyMicroCT2020}}
	\label{fig:ct-projections}
\end{figure}

\subsection{Data processing}
\label{s:b-mct-processing}
Once all needed projections, as shown in \cref{fig:ct-projections}, are performed and stored on a computer, they can be reconstructed into the final image, or in the case of a volume dataset multiple images \cite{liMicrocomputedTomographySmall2008,orhanMicrocomputedTomographyMicroCT2020}.
A single projection can be described as a radiograph (image), which represents the intensity of the object at a particular angle \cite{liMicrocomputedTomographySmall2008,orhanMicrocomputedTomographyMicroCT2020}.
The radiographs differentiate either 65,536 (16-\gls{bit}) grey values or 256 (8-\gls{bit}) grey values, which are directly related to the X-ray absorption \cite{liMicrocomputedTomographySmall2008,orhanMicrocomputedTomographyMicroCT2020}.
To convert these two-dimensional radiographs into a three-dimensional dataset, the application of a reconstruction algorithm is required.
Multiple reconstruction methods exist, such as fourier or fast fourier, filtered back projection and iterative methods \cite{liMicrocomputedTomographySmall2008,orhanMicrocomputedTomographyMicroCT2020}.
Before any reconstruction algorithm can be utilized the data needs to be preprocessed.
This step compensates for factors such as detector response heterogeneity, defective pixels, X-ray intensity drift and electronic noise \cite{liMicrocomputedTomographySmall2008}.
Next, the reconstruction algorithm can be applied.
As mentioned above, there exist a multitude of reconstructed algorithms, however,
the most widely used algorithm in \mct\space is the \acrfull{fbp}.
Specifically, the \acrfull{fdk}, which is well suited for \mct\space because of its simplicity
and ability to handle data truncation in the z-axis or longitudinal direction \cite{liMicrocomputedTomographySmall2008,orhanMicrocomputedTomographyMicroCT2020}.
Building upon these simple algorithms, are iterative algorithm like the \gls{isra} and \gls{isratv},
which were utilized to reconstruct the datasets used in this study (see: \cref{tab:scan-parameters}).
As can be seen in \cref{fig:isra}, this algorithm starts of by performing a \acrshort{fbp} (bottom right \cref{fig:isra}) and storing the result.
Next, the current image is forward and back-projected  to get an estimation image,
which then serves to calculate the error ratio between the estimation and the measured data.
The error is then considered in the next iteration of forward and back-projection to update the estimate image.
In case of the \gls{isratv}, which is used to improve reconstruction results for datasets with only a small number of projections,
\acrfull{tv} enforces a sparse image gradient.
Effectively, this modification of the \gls{isra} algorithm, enforces uniformity between edges \cite{vandeghinsteLowDoseMicroCTImaging2013}.
\cref{fig:isra} shows \acrshort{tv} being used to enhance the \gls{isra} method by
calculating the \acrshort{tv} on the previous back-projected image and modifying the error ratio for the next iteration cycle \cite{vandeghinsteLowDoseMicroCTImaging2013}.
\begin{figure}[h]
	\centerline{
		\includegraphics[scale=0.5]{images/isra.png}}
	\caption{\gls{isra} and \gls{isratv} iterative algorithm principle \cite{vandeghinsteLowDoseMicroCTImaging2013}}
	\label{fig:isra}
\end{figure}
\noindent
\cref{fig:alg-comp} shows a comparison of reconstruction results between \gls{fdk}, \gls{isra} and \gls{isratv}
in relation to the number of projection views.
When comparing the algorithms results with the lowest number (32) of projection views,
it can be clearly seen that \gls{fdk} suffers the most from streak artifacts and image noise.
\gls{isra} is able to correct for most streak artifacts, but still struggles with image noise.
Finally, \gls{isratv} is able to correct for streak artifacts and image noise \cite{vandeghinsteLowDoseMicroCTImaging2013}.
\begin{figure}[h]
	\centerline{
		\includegraphics[scale=0.5]{images/alg-comp.png}}
	\caption{\gls{fdk}, \gls{isra} and \gls{isratv} comparison \cite{vandeghinsteLowDoseMicroCTImaging2013}}
	\label{fig:alg-comp}
\end{figure}

\subsection{\acrfull{hu}}
\label{s:b-hu}
\acrfull{hu} are directly related to the \acrfull{ac} $\mu$
and can also be called the CT number.
\begin{equation} \label{eqn:hu}
	\acrshort{hu} = \frac{\mu - \mu_{water}}{\mu_{water}}*1000
\end{equation}
\noindent
\cref{eqn:hu} shows how \acrshort{hu} are computed.
Where, $\mu$ is the \acrlong{ac} of a specific tissue or material and $\mu_{water}$
is the \acrlong{ac} of water.
It is calculated as the difference of the \acrlong{ac} of a tissue and water,
divided by the \acrshort{ac} of water and finally multiplied by the factor $1000$ \cite{liMicrocomputedTomographySmall2008}.
Effectively, all \acrshort{hu} values are calculated as a comparison to the \acrlong{ac} of water.
This results in some notable \acrshort{hu} values on the Houndsfield scale.
The most notable one being water, which is zero by definition of \cref{eqn:hu}.
Air, which has an \acrlong{ac} close to zero, has the \acrshort{hu} value of $-1000$.
Bone tissue, which has about twice the \acrlong{ac} of water, has a CT number of $+1000$.
While most soft tissues have a \acrshort{hu} value between $-100$ and $+100$ \cite{liMicrocomputedTomographySmall2008}.

\section{Composition of a guide}
\label{s:guide-creation}

\subsection{\diatx}
\label{s:diataxis}
The structure of the guide was modeled after the ``\diatx\space documentation framework'' by Daniele Procida \cite{procidaDiataxisDocumentationFramework2023,aghajaniSoftwareDocumentationPractitioners2020}.
This framework is extensively used for technical documentation by software projects like NumPy \cite{harrisArrayProgrammingNumPy2020}, Django \cite{Django2013} and large companies like Canonical (Canonical Limited, Douglas, Isle of Man) and Cloudflare (Cloudflare, Inc., San Francisco, California, U.S.A.).
\diatx\space bases itself upon four basic concepts to divide documentation into four different types with different structures according to their goals.\\
\begin{figure}
	\begin{center}
		\begin{tikzpicture}
			\draw [<-,thick,align=center] (-6, 0) -- (0,0) node[midway,above] (acq) {Acquisition (Serves study)};
			\draw [->,thick,align=center] (0, 0) -- (6,0) node[midway,above] (app) {Application (Serves work)};
			\draw [<-,thick,align=center] (0, -7) -- (0,0) node[midway,below,sloped] (cog) {Cognition (Theoretical knowledge)};
			\draw [->,thick,align=center] (0, 0) -- (0,7) node[midway,below,sloped] (act) {Action (Practical steps)};
			\node[below = 2cm of app] (ref) {Reference};
			\node[orange, above = 0.1cm of ref] {Information-oriented};
			\node[below = 2cm of acq] (ex) {Explanation};
			\node[orange, above = 0.1cm of ex] {Understanding-oriented};
			\node[above = 2cm of app] (how) {How-to-guides};
			\node[orange, below = 0.1cm of how] {Task-oriented};
			\node[above = 2cm of acq] (tut) {Tutorials};
			\node[orange, below = 0.1cm of tut] {Learning-oriented};
		\end{tikzpicture}
	\end{center}
	\label{fig:diataxis-foundation}
	\caption{\diatx\space Foundations \cite{procidaDiataxisDocumentationFramework2023}}
\end{figure}
\noindent
As can be seen in \cref{fig:diataxis-foundation}, the documentation author first ought to decide which scale their documentation applies to.
As the target audience may be interested in practical or theoretical knowledge, the documentation author traces the y-axis of \cref{fig:diataxis-foundation} in positive or negative direction.
\citeauthor{procidaDiataxisDocumentationFramework2023} then instructs documentation authors to decide if their target audience is interested in documentation that either serves further study or leads to directly applicable practical knowledge.
Documentation authors should therefore trace the x-axis of \cref{fig:diataxis-foundation} in positive or negative direction, finally arriving at the type of documentation they should compose for the task at hand \cite{procidaPythonDocsCommunity2022}.
\citeauthor{procidaDiataxisDocumentationFramework2023} explains the purpose of his four types of documentation as follows:
\begin{description}
	\item[Tutorial] Teaches user in basic competence in a skill by having them follow practical steps.
	\item[How-to guide] Helps users apply their skill to solve actual problems by showing steps.
	\item[Explanation] Helps users understand theoretical concepts about their skill.
	\item[Reference] Gives the user information about a skill without outlining the steps they need to take.
\end{description}
Additionally, \citeauthor{procidaDiataxisDocumentationFramework2023} mentions that these types do not pose hard limits on what documentation can contain. They are rather meant to remind the author about the needs of users.
According to these criteria the guides practical section is based on \citeauthor{procidaDiataxisDocumentationFramework2023}s structure for How-to guides, and its theoretical section is based on his structure for Explanation style documentation.

\subsubsection*{How-to guide}
\citeauthor{procidaDiataxisDocumentationFramework2023} implores that How-to guides need to have practical utility and a clear objective.
They can only serve an already competent user.
Thus, the guide on page \pageref{a:guide} has explanations about the basic usage of 3D Slicer and its tools before instructing the user to follow a segmentation method themselves.
\citeauthor{procidaDiataxisDocumentationFramework2023} requires How-to guides to feature imperative language that does not allow for digression or explanation \cite{procidaPythonDocsCommunity2022,procidaDiataxisDocumentationFramework2023}.

\subsubsection*{Explanation}
Explanation documentation according to \citeauthor{procidaDiataxisDocumentationFramework2023} on the other hand is defined as offering context to users.
It is supposed to establish connections between concepts and deepen the users theoretical understanding of the skill
While also offering the user choices and reasons to do something a particular way, or even explain why something is not recommended \cite{procidaPythonDocsCommunity2022,procidaDiataxisDocumentationFramework2023}.

\subsection{Pictograms}
\label{s:b-pictograms}
The guide, which can be seen on page: \pageref{a:guide}, makes extensive use of pictograms to inform the reader about common errors, pitfalls to avoid, warn about resource intensive operations and weather a tool is only available via an add-on.
Inspiration for this kind of visual communication was taken from books published by O'Reilly Media, Inc., specifically ``Linux observability with \acrshort{bpf}: advanced programming for performance analysis and networking'' by David Calavera and Lorenzo Fontana \cite{calaveraLinuxObservabilityBPF2019}.
Pictograms are stylized drawings that are supposed to represent familiar objects, ideas or abstract concepts to the reader \cite{dowsePharmacistsAreWords2021}.
In health information documents, they have been proven to enhance readability, attractiveness and visual attention of the target audience \cite{houtsRolePicturesImproving2006,mansoorEffectPictogramsReadability2003}.\\

\section{Segmentation of images and volumes}
\label{s:b-segmentation-basics}
% (TODO: explain how segmentations are represented)

% https://slicer.readthedocs.io/en/latest/user_guide/image_segmentation.html

% https://pdf.sciencedirectassets.com/276826/1-s2.0-S1002007108X00061/1-s2.0-S1002007108000658/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEIH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIC0651E8f8wYnatuSWoH5B6QUXpJl5MbGRvWCkKGH3eIAiBvnyYEsTNrvIQIGrGVLvmFluaWtP7WINLlnbDCpX46xSq8BQi5%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAUaDDA1OTAwMzU0Njg2NSIM1STppGJCBYoUEBeVKpAFWAcGFyUcG0btJR%2FneE3O%2BBlTxy7E5ofkZHmqUQwnBVCsLpchDXvIfS1JRiLoVLZiyut6RbzSQ1yXcHQVTGvXSkrIXaFJLUgzlOV2P5cA0z9otXoyMxNKJe9b3M5%2Bri6HwsjS2tecJoVGp9I%2Fxt5Vto%2B%2BW9l6a%2B6mikvKuxRzl1A5ymZbAXBeweI3NOXYN%2F0mGMzxLCe5LZKPlleOf6PhI%2B%2Fn38ROevhlXMzKa7lBUNQrmxUY5PItKNCVCqpGOx8iaHxVwbA%2BvqDdjIgE1gWp57P4Ws0QQQWzjEFPkr%2FQtc%2F5QW5zYun9A59QfK0rzVYYifEXXwILRVPdIJnObDY0t8zkqON%2F%2FbETulttNw7QtMG%2FyXxPkP2cbZXFPg28T%2BdBEAXQpPR7aRqyhZwCS5%2FiO%2BFvdO0U59U9bJFKWxbf%2BrRbCzSCCjIQhbu85L8Iaw7mW9KqFlDbxjFsjn1gofo7YAaG7FkBZrto%2BtdicJU3VQu01UrUMXuYDHr6iuFiwpBVIspyaTnq0xkBMz8uD4mniBMfTszP%2FGpobudWY2PT9Aiq2peJN%2FKSr%2FqfpA3iQoJIuTxvlAlEXTDmQSUW7JLuQWakWZagmARMJM8BMPMJZyGRd1yvW%2Ba97uUq8C874DWzhJtC3bnHl1bs0sCt5kXy9wgR%2Fc7juoY6ww76MjVPj9PRXXSsNPIgm64srDQIpk791E8PX%2B2osKa3HTxi82IrSaBjFdd3%2F0t%2FqbUol5MlvZCDiQDuJZuMIIE12ZNf9zViJOAc2twSKTH6esVAD8tquVviw9Y16yfmo6E56J%2BBvPuDqD9xLSkVsKbMIngZtGjvxZr9NYWUuDzs3yZqLnzWD7N9Zx2xQvgkgrqLqRLSTo0w18TEtwY6sgFg2sYrBVEID6iQHkMLCCHBShdm0l0WNHPr%2FVBXRSU2aHYR8wp7pP9IjKVw3IPSSCCz4i2Mbc%2BYSpTvjEch5dhv5%2FyVMG%2Fp0hIpijQTajDlXOCIb4hiEzk5L2ar77cZfxUSNJfCM7srS7gCzG0K5ZYZAEf29r16H85UcDMyejTA1FvEQGJ%2B3KnYr1gy0DzAy7gB5C%2F%2Fjf7gh%2BvbMFv0Xtv%2FKvrCWMnV2Jzyyu6ndkg%2BHlZU&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20240923T084001Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYV3XLASKH%2F20240923%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=e8cf422cc462ca2f9cc477cbdea04e2e7c981543eec928e444da7d58b9d58564&hash=297d50f9d1f50c00ae81b7c033038ede324643f9d36bd7eb5099a63fd99c4816&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1002007108000658&tid=spdf-f0276a20-ff46-4f00-a9af-e2bccba738f8&sid=b1fc4ae88be0f942df7a2d8859741e612e47gxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=1b125f02555f530f530257&rr=8c793a3f998ac2aa&cc=at

% https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0068449&type=printable

% https://sci-hub.st/10.1007/978-3-030-16641-0
\section{Mouse bone anatomy}
\label{s:b-mouse-anatomy}
